{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Introduction to spaCy for Advanced NLP -->\n",
    "\n",
    "spaCy is an open-source library for advanced natural language processing (NLP) tasks in Python. \n",
    "\n",
    "It's designed to be fast, efficient, and production-ready, making it a popular choice for professionals and researchers working on various NLP projects. \n",
    "\n",
    "spaCy provides a range of tools and features for tasks such as tokenization, part-of-speech tagging, named entity recognition, dependency parsing, and more. \n",
    "\n",
    "Here's an introduction to spaCy and its key features:\n",
    "\n",
    "Key Features of spaCy:\n",
    "\n",
    "1. Efficient Tokenization: spaCy's tokenization is highly efficient and accurate. \n",
    "\n",
    "    It can split text into words, punctuation marks, and more, making it suitable for various NLP tasks.\n",
    "\n",
    "2. Part-of-Speech Tagging: spaCy can assign part-of-speech tags (e.g., noun, verb, adjective) to each word in a sentence, \n",
    "\n",
    "    which is valuable for syntactic analysis and understanding sentence structure.\n",
    "\n",
    "3. Named Entity Recognition (NER): spaCy can identify and classify\n",
    "\n",
    "    named entities in text, such as names of people, organizations, locations, dates, and more.\n",
    "\n",
    "4. Dependency Parsing: Dependency parsing in spaCy helps analyze the grammatical structure of a \n",
    "\n",
    "    sentence by providing information on word relationships, subject-verb relationships, and more.\n",
    "\n",
    "5. Lemmatization: spaCy can perform lemmatization, which reduces words to their base or dictionary form. \n",
    "\n",
    "    This is useful for text normalization.\n",
    "\n",
    "6. Text Classification: spaCy supports text classification tasks, making it suitable for sentiment analysis, \n",
    "\n",
    "    topic classification, and other classification tasks.\n",
    "\n",
    "7. Custom Pipelines: Users can create custom processing pipelines by adding their own functions to spaCy's processing pipeline. \n",
    "\n",
    "    This allows for customization and extensibility.\n",
    "\n",
    "8. Pretrained Word Vectors: spaCy provides access to pretrained word vectors, such as Word2Vec and GloVe embeddings, \n",
    "\n",
    "    which can enhance the performance of NLP models.\n",
    "\n",
    "9. Multilingual Support: spaCy supports multiple languages and is designed to handle text in various languages efficiently.\n",
    "\n",
    "10. Named Entity Recognition Training: Users can train custom NER models on domain-specific data using spaCy's training capabilities.\n",
    "\n",
    "11. Integration with Deep Learning: spaCy can be integrated with deep learning frameworks like TensorFlow and PyTorch, \n",
    "\n",
    "    allowing for the development of complex NLP models.\n",
    "\n",
    "* Getting Started with spaCy:\n",
    "\n",
    "    Here are steps to get started with spaCy:\n",
    "\n",
    "    Installation: You can install spaCy using pip:\n",
    "\n",
    "# pip install spacy\n",
    "\n",
    "* Language Models: spaCy requires language models for specific languages. \n",
    "\n",
    "    You can download a language model using the following command \n",
    "    \n",
    "    (replace 'en' with the code for your desired language):\n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "* Usage: After installation and model download, you can start using spaCy in your Python script or Jupyter Notebook. \n",
    "\n",
    "    Import spaCy, load the language model, and process text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 18:21:50.263337: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-21 18:21:50.533086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-21 18:21:51.349017: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# Load the English language model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39men_core_web_sm\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Process text\u001b[39;00m\n\u001b[1;32m     11\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mApple Inc. is planning to open a new store in Paris.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     52\u001b[0m         name,\n\u001b[1;32m     53\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m     54\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m     55\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m     56\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m     57\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m     58\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    471\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# Example of spaCy Usage:\n",
    "\n",
    "# Here's an example of how to use spaCy to perform tokenization, part-of-speech tagging, and named entity recognition:\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process text\n",
    "text = \"Apple Inc. is planning to open a new store in Paris.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Tokenization\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "\n",
    "# Part-of-Speech Tagging\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)\n",
    "\n",
    "# Named Entity Recognition\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "\n",
    "# This code will tokenize the text, provide part-of-speech tags for each word, and recognize \"Apple Inc.\" \n",
    "# as an organization and \"Paris\" as a location.\n",
    "\n",
    "# spaCy is a powerful library for advanced NLP tasks and is widely used in research and industry for tasks like text analysis, information extraction, and language understanding. \n",
    "# Its speed and efficiency make it an excellent choice for production applications that require high-performance NLP capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
